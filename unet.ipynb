{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODltIQ3JUyq5gMMCRyT1qA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SrivastavaHarsit/Satellite-Image-Segmentation/blob/main/unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZN5FvFES_MbQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.nn.modules.activation import Sigmoid\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import random\n",
        "from random import shuffle\n",
        "import math\n",
        "\n",
        "import cv2 as cv\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxLAeL93_ZVF",
        "outputId": "916c4b56-548d-4e38-b998-53d20e520664"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "\n",
        "files.upload()\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download bulentsiyah/semantic-drone-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5UrJ_PX_eNT",
        "outputId": "91b94754-6fa2-4267-d562-8f845578f46e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "401 - Unauthorized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/semantic-drone-dataset.zip"
      ],
      "metadata": {
        "id": "IM8OKZRnFGg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs = []\n",
        "labels = []\n",
        "for i, img in enumerate(glob.glob('/content/dataset/semantic_drone_dataset/original_images/*')):\n",
        "  img = cv.cvtColor(cv.resize(cv.imread(img), (512, 512)), cv.COLOR_BGR2GRAY)/255\n",
        "  imgs.append(img)\n",
        "  # print(i)\n",
        "  if i >= 50:\n",
        "    break\n",
        "\n",
        "for i, img in enumerate(glob.glob('/content/dataset/semantic_drone_dataset/label_images_semantic/*')):\n",
        "  img = cv.cvtColor(cv.resize(cv.imread(img), (512, 512)), cv.COLOR_BGR2GRAY)/255\n",
        "  labels.append(img)\n",
        "  if i >= 50:\n",
        "    break"
      ],
      "metadata": {
        "id": "FIGrGS6RFIXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = DataLoader(list(zip(imgs, labels)), batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "XUzznlCjFIfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class encoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(encoder, self).__init__()\n",
        "\n",
        "    self.encoder = nn.Sequential(\n",
        "        nn.Conv2d(1, 256, kernel_size=5, stride=3, padding=1), # N, 64, 14, 14\n",
        "        nn.SELU(),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.Conv2d(256, 128, kernel_size=5, stride=3, padding=1), # N, 128, 7, 7\n",
        "        nn.SELU(),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.Conv2d(128, 64, kernel_size=7), # N, 64, 1, 1\n",
        "        nn.SELU()\n",
        "    )\n",
        "    self.fc = nn.Linear(64*50*50, 32)\n",
        "    self.drop = nn.Dropout(0.4)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = self.encoder(x)\n",
        "    x = x.view(-1, 64*50*50)\n",
        "    x = self.drop(self.fc(x))\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "class decoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(decoder, self).__init__()\n",
        "\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.ConvTranspose2d(64, 128, 7), # N, 128, 7, 7\n",
        "        nn.SELU(),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ConvTranspose2d(128, 256, 5, stride=3, padding=1, output_padding=2), # N, 64, 14, 14\n",
        "        nn.SELU(),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ConvTranspose2d(256, 1, 5, stride=3, padding=1, output_padding=2),  # N, 1, 28, 28\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "    self.initial = nn.Linear(32, 64*50*50)\n",
        "    self.drop = nn.Dropout(0.4)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.drop(self.initial(x))\n",
        "    x = x.view(-1, 64, 50, 50)\n",
        "    x = self.decoder(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "9WLPr7IsFIni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "print(summary(encoder(), (64,1,512,512)))\n",
        "print(summary(decoder(), (64, 32)))"
      ],
      "metadata": {
        "id": "JWQ8PGpPFIuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch.nn.functional as F\n",
        "##ssim loss function\n",
        "\n",
        "def gaussian(window_size, sigma):\n",
        "    \"\"\"\n",
        "    Generates a list of Tensor values drawn from a gaussian distribution with standard\n",
        "    diviation = sigma and sum of all elements = 1.\n",
        "\n",
        "    Length of list = window_size\n",
        "    \"\"\"\n",
        "    gauss =  torch.Tensor([math.exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
        "    return gauss/gauss.sum()\n",
        "\n",
        "def create_window(window_size, channel=1):\n",
        "\n",
        "    # Generate an 1D tensor containing values sampled from a gaussian distribution\n",
        "    _1d_window = gaussian(window_size=window_size, sigma=1.5).unsqueeze(1)\n",
        "\n",
        "    # Converting to 2D\n",
        "    _2d_window = _1d_window.mm(_1d_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "    window = torch.Tensor(_2d_window.expand(channel, 1, window_size, window_size).contiguous())\n",
        "\n",
        "    return window\n",
        "\n",
        "def ssim(img1, img2, val_range=1, window_size=11, window=None, size_average=True, full=False):\n",
        "\n",
        "    L = val_range # L is the dynamic range of the pixel values (255 for 8-bit grayscale images),\n",
        "\n",
        "    pad = window_size // 2\n",
        "\n",
        "    try:\n",
        "        _, channels, height, width = img1.size()\n",
        "    except:\n",
        "        channels, height, width = img1.size()\n",
        "\n",
        "    # if window is not provided, init one\n",
        "    if window is None:\n",
        "        real_size = min(window_size, height, width) # window should be atleast 11x11\n",
        "        window = create_window(real_size, channel=channels).to(img1.device)\n",
        "\n",
        "    # calculating the mu parameter (locally) for both images using a gaussian filter\n",
        "    # calculates the luminosity params\n",
        "    mu1 = F.conv2d(img1, window, padding=pad, groups=channels)\n",
        "    mu2 = F.conv2d(img2, window, padding=pad, groups=channels)\n",
        "\n",
        "    mu1_sq = mu1 ** 2\n",
        "    mu2_sq = mu2 ** 2\n",
        "    mu12 = mu1 * mu2\n",
        "\n",
        "    # now we calculate the sigma square parameter\n",
        "    # Sigma deals with the contrast component\n",
        "    sigma1_sq = F.conv2d(img1 * img1, window, padding=pad, groups=channels) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(img2 * img2, window, padding=pad, groups=channels) - mu2_sq\n",
        "    sigma12 =  F.conv2d(img1 * img2, window, padding=pad, groups=channels) - mu12\n",
        "\n",
        "    # Some constants for stability\n",
        "    C1 = (0.01 ) ** 2  # NOTE: Removed L from here (ref PT implementation)\n",
        "    C2 = (0.03 ) ** 2\n",
        "\n",
        "    contrast_metric = (2.0 * sigma12 + C2) / (sigma1_sq + sigma2_sq + C2)\n",
        "    contrast_metric = torch.mean(contrast_metric)\n",
        "\n",
        "    numerator1 = 2 * mu12 + C1\n",
        "    numerator2 = 2 * sigma12 + C2\n",
        "    denominator1 = mu1_sq + mu2_sq + C1\n",
        "    denominator2 = sigma1_sq + sigma2_sq + C2\n",
        "\n",
        "    ssim_score = (numerator1 * numerator2) / (denominator1 * denominator2)\n",
        "\n",
        "    if size_average:\n",
        "        ret = ssim_score.mean()\n",
        "    else:\n",
        "        ret = ssim_score.mean(1).mean(1).mean(1)\n",
        "\n",
        "    if full:\n",
        "        return ret, contrast_metric\n",
        "\n",
        "    return ret\n",
        "\n",
        "\n",
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomLoss, self).__init__()\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        target = torch.Tensor(target)\n",
        "        loss = ssim(output, target)\n",
        "        return -loss"
      ],
      "metadata": {
        "id": "wgqwOLMRFI1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en = encoder().to(device)\n",
        "dec = decoder().to(device)\n",
        "criterion = CustomLoss()\n",
        "en_optim = Adam(en.parameters(), lr=0.001)\n",
        "de_optim = Adam(dec.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "GIO2anDWFUWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=20\n",
        "outputs=[]\n",
        "for epoch in range(num_epochs):\n",
        "  en.train()\n",
        "  dec.train()\n",
        "  for (img, label) in data_loader:\n",
        "    img = img.to(device).float().unsqueeze(1)\n",
        "    label = label.to(device).float().unsqueeze(1)\n",
        "    # print(img.size())\n",
        "    encoded = en(img)\n",
        "    recon = dec(encoded)\n",
        "    loss = criterion(recon, label)\n",
        "\n",
        "    en_optim.zero_grad()\n",
        "    de_optim.zero_grad()\n",
        "    loss.backward()\n",
        "    en_optim.step()\n",
        "    de_optim.step()\n",
        "\n",
        "  print(f\"Epoch: {epoch}, loss: {loss.item()}\")\n",
        "  outputs.append((epoch, img, recon))"
      ],
      "metadata": {
        "id": "2dHWNGSBFUeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(outputs[19][1][0].detach().cpu().numpy().squeeze())"
      ],
      "metadata": {
        "id": "0mj0nG9nFUkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(outputs[19][2][0].detach().cpu().numpy().squeeze())"
      ],
      "metadata": {
        "id": "674ybz87FUsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "torch.save(en, '/content/imgen.pt')\n",
        "torch.save(dec, '/content/imgdec.pt')\n",
        "files.download('/content/imgen.pt')\n",
        "files.download('/content/imgdec.pt')"
      ],
      "metadata": {
        "id": "-Jpvxvz3FJIh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}